{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Holteiu_N_Daniel_Ninel_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Breed Name   Weight(g)  Height(cm)  Longevity(yrs) Energy level  \\\n",
      "0                Amstaff  27412.4472     46.4779         12.7271          med   \n",
      "1                Amstaff  33302.6172         NaN         12.9844          low   \n",
      "2       Airedale Terrier  19184.9322     57.7801         10.1529         high   \n",
      "3                Amstaff  26228.6536     45.6682         13.5366          low   \n",
      "4              Daschhund   7720.7755     20.1153         13.8247         high   \n",
      "5       Airedale Terrier  20379.5337     57.5140         10.2833         high   \n",
      "6       Airedale Terrier  21246.1613         NaN         11.4508         high   \n",
      "7       Airedale Terrier  21491.1460     56.7838         12.8966         high   \n",
      "8       Airedale Terrier  21740.7510         NaN         11.4410         high   \n",
      "9    Jack Russel Terrier   6820.8519     33.5175         13.6113         high   \n",
      "10               Amstaff  23545.6745         NaN         13.1212          med   \n",
      "11             Daschhund  14489.3409     20.8370         13.5397         high   \n",
      "12               Amstaff  27870.3226     46.1721         13.0982          med   \n",
      "13   Jack Russel Terrier   5781.6924         NaN         14.5575         high   \n",
      "14      Airedale Terrier  18222.0316     56.9236         10.2664         high   \n",
      "15             Daschhund  14639.3281     20.5574         13.2471         high   \n",
      "16   Jack Russel Terrier   5891.8975     33.7275         13.4918         high   \n",
      "17      Airedale Terrier  22944.6667     56.8545         11.2131         high   \n",
      "18      Airedale Terrier  20387.9993     57.0346         10.8801          med   \n",
      "19   Jack Russel Terrier   6195.4468     33.3480         15.1374         high   \n",
      "20      Airedale Terrier  19197.6377     56.7990          9.9128         high   \n",
      "21      Airedale Terrier  22062.7100         NaN         11.6038         high   \n",
      "22   Jack Russel Terrier   6772.6109     34.4892         14.9422         high   \n",
      "23               Amstaff  27069.5952     46.0445         13.5513         high   \n",
      "24   Jack Russel Terrier   7085.7969     34.0145         14.2225         high   \n",
      "25               Amstaff  30371.2457     46.0058         12.0043          med   \n",
      "26   Jack Russel Terrier   8070.9800         NaN         13.9047         high   \n",
      "27   Jack Russel Terrier   5683.7821     34.3349         13.9714         high   \n",
      "28             Daschhund   8173.7912     21.5752         12.9213         high   \n",
      "29      Airedale Terrier  21375.9899     57.0617         12.4133         high   \n",
      "..                   ...         ...         ...             ...          ...   \n",
      "970              Amstaff  29717.5202     46.1089         12.9650          med   \n",
      "971  Jack Russel Terrier   6471.2563     35.4692         13.8880         high   \n",
      "972  Jack Russel Terrier   7428.3210     34.8833         14.3188         high   \n",
      "973              Amstaff  29947.5342     46.8357         11.9766          med   \n",
      "974              Amstaff  19832.2147     45.8950         13.2507          med   \n",
      "975              Amstaff  23605.4947     46.7785         13.1943          low   \n",
      "976  Jack Russel Terrier   5386.3058     34.4775         14.8145         high   \n",
      "977  Jack Russel Terrier   6592.6675     34.4870         13.3046         high   \n",
      "978            Daschhund  13574.4412     20.1083         13.7816         high   \n",
      "979  Jack Russel Terrier   7164.9452     34.5533         14.2401         high   \n",
      "980     Airedale Terrier  22012.6106     57.7233         11.6081         high   \n",
      "981            Daschhund   8847.6432     20.8950         13.5220         high   \n",
      "982  Jack Russel Terrier   5841.9292         NaN         13.3790          med   \n",
      "983     Airedale Terrier  20652.8986     56.8116         12.5771          med   \n",
      "984              Amstaff  23348.2792     46.5524         12.4119          med   \n",
      "985            Daschhund   7187.5568     21.4954         13.3620         high   \n",
      "986            Daschhund  10361.1677     20.2664         11.9504         high   \n",
      "987  Jack Russel Terrier   5008.3757     33.1474         13.3220         high   \n",
      "988            Daschhund   6613.5174     20.2383         12.8570         high   \n",
      "989     Airedale Terrier  21328.1791     57.3835         11.5995         high   \n",
      "990            Daschhund   8992.4889     21.2831         12.1729         high   \n",
      "991     Airedale Terrier  20368.0889     56.8945         11.5040         high   \n",
      "992     Airedale Terrier  18205.4872     56.5899         10.9126         high   \n",
      "993            Daschhund   4771.1665     20.7992         12.4886         high   \n",
      "994  Jack Russel Terrier   6850.8759     33.5483         13.6792         high   \n",
      "995              Amstaff  27774.3222         NaN         13.6471          med   \n",
      "996  Jack Russel Terrier   7918.2192     34.0478         13.8639         high   \n",
      "997            Daschhund  13340.7933     21.5531         11.9293         high   \n",
      "998     Airedale Terrier  20505.2008         NaN         11.7436         high   \n",
      "999  Jack Russel Terrier   6642.2769     33.3306         13.7579         high   \n",
      "\n",
      "    Attention Needs Coat Lenght     Sex  Owner Name  \n",
      "0              high       short    male      Mosley  \n",
      "1               med       short  female       Crane  \n",
      "2              high         med  female      Thomas  \n",
      "3               med         med  female      Oliver  \n",
      "4               med       short    male    Williams  \n",
      "5              high       short    male     Hoffman  \n",
      "6              high         med    male     Herrera  \n",
      "7              high         med    male    Cardenas  \n",
      "8              high       short  female     Johnson  \n",
      "9               med       short  female    Campbell  \n",
      "10             high       short    male        Hart  \n",
      "11              med       short    male   Gillespie  \n",
      "12              med       short  female     Roberts  \n",
      "13              med       short  female      Harris  \n",
      "14             high         med  female    Faulkner  \n",
      "15              med         med  female       Clark  \n",
      "16              med       short    male     Griffin  \n",
      "17             high        long  female         Cox  \n",
      "18             high         med  female     Vasquez  \n",
      "19              med       short  female      Garcia  \n",
      "20              med         med  female      Keller  \n",
      "21             high         med  female     Johnson  \n",
      "22              med         med    male        King  \n",
      "23             high       short    male       Kelly  \n",
      "24              low       short  female      Rogers  \n",
      "25              med         med  female       Allen  \n",
      "26              low       short    male    Thompson  \n",
      "27              med         med  female      Flores  \n",
      "28             high       short  female        Hall  \n",
      "29             high         med    male         Cox  \n",
      "..              ...         ...     ...         ...  \n",
      "970            high       short  female     Stewart  \n",
      "971             med       short  female       Brown  \n",
      "972             med       short  female    Thompson  \n",
      "973            high       short    male        Love  \n",
      "974            high       short    male      Howard  \n",
      "975            high       short    male      Lawson  \n",
      "976             med       short  female  Washington  \n",
      "977             med       short    male      Keller  \n",
      "978             med       short    male       Blake  \n",
      "979             med       short    male      Garcia  \n",
      "980            high         med    male     Bennett  \n",
      "981             med       short    male       Berry  \n",
      "982             med       short    male     Coleman  \n",
      "983            high       short  female    Martinez  \n",
      "984            high       short    male       Moore  \n",
      "985            high       short    male       Davis  \n",
      "986             med       short  female    Bradshaw  \n",
      "987            high       short    male      Knight  \n",
      "988             med       short  female     Edwards  \n",
      "989            high         med    male       Meyer  \n",
      "990             med       short  female     Mcmahon  \n",
      "991            high        long  female       Marsh  \n",
      "992             med        long    male       Young  \n",
      "993            high       short  female     Farrell  \n",
      "994            high       short    male     Sanchez  \n",
      "995            high       short    male     Coleman  \n",
      "996             low       short    male      Moreno  \n",
      "997             med       short    male    Reynolds  \n",
      "998            high         med  female       Smith  \n",
      "999             med       short  female      Miller  \n",
      "\n",
      "[1000 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Breed Name   Weight(g)  Height(cm) Energy level Attention Needs  \\\n",
      "0             1  27412.4472     46.4779          med            high   \n",
      "1             1  33302.6172         NaN          low             med   \n",
      "2             2  19184.9322     57.7801         high            high   \n",
      "3             1  26228.6536     45.6682          low             med   \n",
      "4             0   7720.7755     20.1153         high             med   \n",
      "5             2  20379.5337     57.5140         high            high   \n",
      "6             2  21246.1613         NaN         high            high   \n",
      "7             2  21491.1460     56.7838         high            high   \n",
      "8             2  21740.7510         NaN         high            high   \n",
      "9             3   6820.8519     33.5175         high             med   \n",
      "10            1  23545.6745         NaN          med            high   \n",
      "11            0  14489.3409     20.8370         high             med   \n",
      "12            1  27870.3226     46.1721          med             med   \n",
      "13            3   5781.6924         NaN         high             med   \n",
      "14            2  18222.0316     56.9236         high            high   \n",
      "15            0  14639.3281     20.5574         high             med   \n",
      "16            3   5891.8975     33.7275         high             med   \n",
      "17            2  22944.6667     56.8545         high            high   \n",
      "18            2  20387.9993     57.0346          med            high   \n",
      "19            3   6195.4468     33.3480         high             med   \n",
      "20            2  19197.6377     56.7990         high             med   \n",
      "21            2  22062.7100         NaN         high            high   \n",
      "22            3   6772.6109     34.4892         high             med   \n",
      "23            1  27069.5952     46.0445         high            high   \n",
      "24            3   7085.7969     34.0145         high             low   \n",
      "25            1  30371.2457     46.0058          med             med   \n",
      "26            3   8070.9800         NaN         high             low   \n",
      "27            3   5683.7821     34.3349         high             med   \n",
      "28            0   8173.7912     21.5752         high            high   \n",
      "29            2  21375.9899     57.0617         high            high   \n",
      "..          ...         ...         ...          ...             ...   \n",
      "970           1  29717.5202     46.1089          med            high   \n",
      "971           3   6471.2563     35.4692         high             med   \n",
      "972           3   7428.3210     34.8833         high             med   \n",
      "973           1  29947.5342     46.8357          med            high   \n",
      "974           1  19832.2147     45.8950          med            high   \n",
      "975           1  23605.4947     46.7785          low            high   \n",
      "976           3   5386.3058     34.4775         high             med   \n",
      "977           3   6592.6675     34.4870         high             med   \n",
      "978           0  13574.4412     20.1083         high             med   \n",
      "979           3   7164.9452     34.5533         high             med   \n",
      "980           2  22012.6106     57.7233         high            high   \n",
      "981           0   8847.6432     20.8950         high             med   \n",
      "982           3   5841.9292         NaN          med             med   \n",
      "983           2  20652.8986     56.8116          med            high   \n",
      "984           1  23348.2792     46.5524          med            high   \n",
      "985           0   7187.5568     21.4954         high            high   \n",
      "986           0  10361.1677     20.2664         high             med   \n",
      "987           3   5008.3757     33.1474         high            high   \n",
      "988           0   6613.5174     20.2383         high             med   \n",
      "989           2  21328.1791     57.3835         high            high   \n",
      "990           0   8992.4889     21.2831         high             med   \n",
      "991           2  20368.0889     56.8945         high            high   \n",
      "992           2  18205.4872     56.5899         high             med   \n",
      "993           0   4771.1665     20.7992         high            high   \n",
      "994           3   6850.8759     33.5483         high            high   \n",
      "995           1  27774.3222         NaN          med            high   \n",
      "996           3   7918.2192     34.0478         high             low   \n",
      "997           0  13340.7933     21.5531         high             med   \n",
      "998           2  20505.2008         NaN         high            high   \n",
      "999           3   6642.2769     33.3306         high             med   \n",
      "\n",
      "    Coat Lenght     Sex  \n",
      "0         short    male  \n",
      "1         short  female  \n",
      "2           med  female  \n",
      "3           med  female  \n",
      "4         short    male  \n",
      "5         short    male  \n",
      "6           med    male  \n",
      "7           med    male  \n",
      "8         short  female  \n",
      "9         short  female  \n",
      "10        short    male  \n",
      "11        short    male  \n",
      "12        short  female  \n",
      "13        short  female  \n",
      "14          med  female  \n",
      "15          med  female  \n",
      "16        short    male  \n",
      "17         long  female  \n",
      "18          med  female  \n",
      "19        short  female  \n",
      "20          med  female  \n",
      "21          med  female  \n",
      "22          med    male  \n",
      "23        short    male  \n",
      "24        short  female  \n",
      "25          med  female  \n",
      "26        short    male  \n",
      "27          med  female  \n",
      "28        short  female  \n",
      "29          med    male  \n",
      "..          ...     ...  \n",
      "970       short  female  \n",
      "971       short  female  \n",
      "972       short  female  \n",
      "973       short    male  \n",
      "974       short    male  \n",
      "975       short    male  \n",
      "976       short  female  \n",
      "977       short    male  \n",
      "978       short    male  \n",
      "979       short    male  \n",
      "980         med    male  \n",
      "981       short    male  \n",
      "982       short    male  \n",
      "983       short  female  \n",
      "984       short    male  \n",
      "985       short    male  \n",
      "986       short  female  \n",
      "987       short    male  \n",
      "988       short  female  \n",
      "989         med    male  \n",
      "990       short  female  \n",
      "991        long  female  \n",
      "992        long    male  \n",
      "993       short  female  \n",
      "994       short    male  \n",
      "995       short    male  \n",
      "996       short    male  \n",
      "997       short    male  \n",
      "998         med  female  \n",
      "999       short  female  \n",
      "\n",
      "[1000 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Getting the list of all \"Breed Names\" and encoding them so to not use Strings\n",
    "breed_list = set(dataset['Breed Name'].tolist())\n",
    "breed_encoding = {}\n",
    "for breed_name, index in zip(breed_list, range(len(breed_list))):\n",
    "    breed_encoding[breed_name] = index\n",
    "modified_dataset = dataset\n",
    "modified_dataset['Breed Name'] = modified_dataset['Breed Name'].map(lambda el: breed_encoding.get(el))\n",
    "# getting rid of Longevity column\n",
    "modified_dataset = modified_dataset.drop('Longevity(yrs)', axis=1)\n",
    "# Also getting rid of Owner Name (makes no sense for us) - Results don't depend on Owner Name\n",
    "modified_dataset = modified_dataset.drop('Owner Name', axis=1)\n",
    "print(modified_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breed Name           0\n",
      "Weight(g)            0\n",
      "Height(cm)         196\n",
      "Energy level         0\n",
      "Attention Needs      0\n",
      "Coat Lenght          0\n",
      "Sex                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Handling Missing Data\n",
    "print(modified_dataset.isnull().sum())\n",
    "modified_dataset = modified_dataset.dropna() # drop missing data\n",
    "modified_dataset = modified_dataset.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Handling Categorical Data\n",
    "# The Categorical Data is handled using One Hot Encoder.\n",
    "categorical_columns = [\"Energy level\", \"Attention Needs\", \"Coat Lenght\", \"Sex\"]\n",
    "for column in categorical_columns:\n",
    "    label_encoder = LabelEncoder()\n",
    "    ohe_encoder = OneHotEncoder()\n",
    "    unique_columns = set(dataset[column].tolist())\n",
    "    unique_columns = {key: value for key, value in zip(range(len(unique_columns)), unique_columns)}\n",
    "    modified_dataset[column + \"_encoded\"] = label_encoder.fit_transform(modified_dataset[column])\n",
    "    aux = ohe_encoder.fit_transform(modified_dataset[column + \"_encoded\"].values.reshape(-1, 1)).toarray()\n",
    "    aux = pd.DataFrame(aux, columns=[column + \"_\" + unique_columns.get(i) for i in range(aux.shape[1])])\n",
    "    modified_dataset = pd.concat([modified_dataset, aux], axis=1)\n",
    "    modified_dataset = modified_dataset.drop(column, axis=1)\n",
    "    modified_dataset = modified_dataset.drop(column + \"_encoded\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization (Just for Weight(g) and Height(cm)). I am using Min Max Normalizer\n",
    "# (X - min(X)) / (max(X) - min(X))\n",
    "modified_dataset[\"Weight(g)\"] = (modified_dataset[\"Weight(g)\"] - modified_dataset[\"Weight(g)\"].min()) / (modified_dataset[\"Weight(g)\"].max() - modified_dataset[\"Weight(g)\"].min())\n",
    "modified_dataset[\"Height(cm)\"] = (modified_dataset[\"Height(cm)\"] - modified_dataset[\"Height(cm)\"].min()) / (modified_dataset[\"Height(cm)\"].max() - modified_dataset[\"Height(cm)\"].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Breed Name  Weight(g)  Height(cm)  Energy level_low  Energy level_med  \\\n",
      "0             1   0.759598    0.684992               0.0               0.0   \n",
      "1             2   0.529946    0.971062               1.0               0.0   \n",
      "2             1   0.726555    0.664498               0.0               1.0   \n",
      "3             0   0.209950    0.017728               1.0               0.0   \n",
      "4             2   0.563290    0.964327               1.0               0.0   \n",
      "5             2   0.594318    0.945845               1.0               0.0   \n",
      "6             3   0.184831    0.356951               1.0               0.0   \n",
      "7             0   0.398879    0.035995               1.0               0.0   \n",
      "8             1   0.772379    0.677252               0.0               0.0   \n",
      "9             2   0.503069    0.949383               1.0               0.0   \n",
      "10            0   0.403066    0.028918               1.0               0.0   \n",
      "11            3   0.158901    0.362266               1.0               0.0   \n",
      "12            2   0.634890    0.947634               1.0               0.0   \n",
      "13            2   0.563527    0.952193               0.0               0.0   \n",
      "14            3   0.167374    0.352661               1.0               0.0   \n",
      "15            2   0.530300    0.946229               1.0               0.0   \n",
      "16            3   0.183484    0.381546               1.0               0.0   \n",
      "17            1   0.750028    0.674022               1.0               0.0   \n",
      "18            3   0.192226    0.369531               1.0               0.0   \n",
      "19            1   0.842186    0.673043               0.0               0.0   \n",
      "20            3   0.153092    0.377640               1.0               0.0   \n",
      "21            0   0.222595    0.054679               1.0               0.0   \n",
      "22            2   0.591104    0.952878               1.0               0.0   \n",
      "23            3   0.172888    0.383176               1.0               0.0   \n",
      "24            0   0.111574    0.023813               1.0               0.0   \n",
      "25            3   0.211218    0.370677               1.0               0.0   \n",
      "26            0   0.274677    0.044859               1.0               0.0   \n",
      "27            1   0.794510    0.671810               0.0               0.0   \n",
      "28            3   0.172960    0.375656               0.0               0.0   \n",
      "29            2   0.559655    0.957290               1.0               0.0   \n",
      "..          ...        ...         ...               ...               ...   \n",
      "774           2   0.548391    0.966817               1.0               0.0   \n",
      "775           1   0.665537    0.672820               0.0               1.0   \n",
      "776           1   0.821460    0.670385               0.0               0.0   \n",
      "777           1   0.823939    0.675652               0.0               0.0   \n",
      "778           3   0.175073    0.406351               1.0               0.0   \n",
      "779           3   0.201787    0.391521               1.0               0.0   \n",
      "780           1   0.830359    0.694048               0.0               0.0   \n",
      "781           1   0.548013    0.670238               0.0               0.0   \n",
      "782           1   0.653336    0.692600               0.0               1.0   \n",
      "783           3   0.144789    0.381250               1.0               0.0   \n",
      "784           3   0.178462    0.381490               1.0               0.0   \n",
      "785           0   0.373342    0.017551               1.0               0.0   \n",
      "786           3   0.194435    0.383168               1.0               0.0   \n",
      "787           2   0.608874    0.969624               1.0               0.0   \n",
      "788           0   0.241404    0.037463               1.0               0.0   \n",
      "789           2   0.570921    0.946548               0.0               0.0   \n",
      "790           1   0.646156    0.686878               0.0               0.0   \n",
      "791           0   0.195067    0.052660               1.0               0.0   \n",
      "792           0   0.283651    0.021552               1.0               0.0   \n",
      "793           3   0.134240    0.347583               1.0               0.0   \n",
      "794           0   0.179044    0.020841               1.0               0.0   \n",
      "795           2   0.589770    0.961024               1.0               0.0   \n",
      "796           0   0.245447    0.047286               1.0               0.0   \n",
      "797           2   0.562971    0.948646               1.0               0.0   \n",
      "798           2   0.502607    0.940937               1.0               0.0   \n",
      "799           0   0.127619    0.035038               1.0               0.0   \n",
      "800           3   0.185669    0.357731               1.0               0.0   \n",
      "801           3   0.215461    0.370373               1.0               0.0   \n",
      "802           0   0.366820    0.054120               1.0               0.0   \n",
      "803           3   0.179846    0.352220               1.0               0.0   \n",
      "\n",
      "     Energy level_high  Attention Needs_low  Attention Needs_med  \\\n",
      "0                  1.0                  1.0                  0.0   \n",
      "1                  0.0                  1.0                  0.0   \n",
      "2                  0.0                  0.0                  0.0   \n",
      "3                  0.0                  0.0                  0.0   \n",
      "4                  0.0                  1.0                  0.0   \n",
      "5                  0.0                  1.0                  0.0   \n",
      "6                  0.0                  0.0                  0.0   \n",
      "7                  0.0                  0.0                  0.0   \n",
      "8                  1.0                  0.0                  0.0   \n",
      "9                  0.0                  1.0                  0.0   \n",
      "10                 0.0                  0.0                  0.0   \n",
      "11                 0.0                  0.0                  0.0   \n",
      "12                 0.0                  1.0                  0.0   \n",
      "13                 1.0                  1.0                  0.0   \n",
      "14                 0.0                  0.0                  0.0   \n",
      "15                 0.0                  0.0                  0.0   \n",
      "16                 0.0                  0.0                  0.0   \n",
      "17                 0.0                  1.0                  0.0   \n",
      "18                 0.0                  0.0                  1.0   \n",
      "19                 1.0                  0.0                  0.0   \n",
      "20                 0.0                  0.0                  0.0   \n",
      "21                 0.0                  1.0                  0.0   \n",
      "22                 0.0                  1.0                  0.0   \n",
      "23                 0.0                  0.0                  0.0   \n",
      "24                 0.0                  0.0                  0.0   \n",
      "25                 0.0                  0.0                  0.0   \n",
      "26                 0.0                  0.0                  0.0   \n",
      "27                 1.0                  1.0                  0.0   \n",
      "28                 1.0                  0.0                  0.0   \n",
      "29                 0.0                  1.0                  0.0   \n",
      "..                 ...                  ...                  ...   \n",
      "774                0.0                  1.0                  0.0   \n",
      "775                0.0                  1.0                  0.0   \n",
      "776                1.0                  1.0                  0.0   \n",
      "777                1.0                  1.0                  0.0   \n",
      "778                0.0                  0.0                  0.0   \n",
      "779                0.0                  0.0                  0.0   \n",
      "780                1.0                  1.0                  0.0   \n",
      "781                1.0                  1.0                  0.0   \n",
      "782                0.0                  1.0                  0.0   \n",
      "783                0.0                  0.0                  0.0   \n",
      "784                0.0                  0.0                  0.0   \n",
      "785                0.0                  0.0                  0.0   \n",
      "786                0.0                  0.0                  0.0   \n",
      "787                0.0                  1.0                  0.0   \n",
      "788                0.0                  0.0                  0.0   \n",
      "789                1.0                  1.0                  0.0   \n",
      "790                1.0                  1.0                  0.0   \n",
      "791                0.0                  1.0                  0.0   \n",
      "792                0.0                  0.0                  0.0   \n",
      "793                0.0                  1.0                  0.0   \n",
      "794                0.0                  0.0                  0.0   \n",
      "795                0.0                  1.0                  0.0   \n",
      "796                0.0                  0.0                  0.0   \n",
      "797                0.0                  1.0                  0.0   \n",
      "798                0.0                  0.0                  0.0   \n",
      "799                0.0                  1.0                  0.0   \n",
      "800                0.0                  1.0                  0.0   \n",
      "801                0.0                  0.0                  1.0   \n",
      "802                0.0                  0.0                  0.0   \n",
      "803                0.0                  0.0                  0.0   \n",
      "\n",
      "     Attention Needs_high  Coat Lenght_long  Coat Lenght_med  \\\n",
      "0                     0.0               0.0              0.0   \n",
      "1                     0.0               0.0              1.0   \n",
      "2                     1.0               0.0              1.0   \n",
      "3                     1.0               0.0              0.0   \n",
      "4                     0.0               0.0              0.0   \n",
      "5                     0.0               0.0              1.0   \n",
      "6                     1.0               0.0              0.0   \n",
      "7                     1.0               0.0              0.0   \n",
      "8                     1.0               0.0              0.0   \n",
      "9                     0.0               0.0              1.0   \n",
      "10                    1.0               0.0              1.0   \n",
      "11                    1.0               0.0              0.0   \n",
      "12                    0.0               1.0              0.0   \n",
      "13                    0.0               0.0              1.0   \n",
      "14                    1.0               0.0              0.0   \n",
      "15                    1.0               0.0              1.0   \n",
      "16                    1.0               0.0              1.0   \n",
      "17                    0.0               0.0              0.0   \n",
      "18                    0.0               0.0              0.0   \n",
      "19                    1.0               0.0              1.0   \n",
      "20                    1.0               0.0              1.0   \n",
      "21                    0.0               0.0              0.0   \n",
      "22                    0.0               0.0              1.0   \n",
      "23                    1.0               0.0              0.0   \n",
      "24                    1.0               0.0              0.0   \n",
      "25                    1.0               0.0              0.0   \n",
      "26                    1.0               0.0              0.0   \n",
      "27                    0.0               0.0              0.0   \n",
      "28                    1.0               0.0              0.0   \n",
      "29                    0.0               0.0              1.0   \n",
      "..                    ...               ...              ...   \n",
      "774                   0.0               0.0              1.0   \n",
      "775                   0.0               0.0              0.0   \n",
      "776                   0.0               0.0              0.0   \n",
      "777                   0.0               0.0              0.0   \n",
      "778                   1.0               0.0              0.0   \n",
      "779                   1.0               0.0              0.0   \n",
      "780                   0.0               0.0              0.0   \n",
      "781                   0.0               0.0              0.0   \n",
      "782                   0.0               0.0              0.0   \n",
      "783                   1.0               0.0              0.0   \n",
      "784                   1.0               0.0              0.0   \n",
      "785                   1.0               0.0              0.0   \n",
      "786                   1.0               0.0              0.0   \n",
      "787                   0.0               0.0              1.0   \n",
      "788                   1.0               0.0              0.0   \n",
      "789                   0.0               0.0              0.0   \n",
      "790                   0.0               0.0              0.0   \n",
      "791                   0.0               0.0              0.0   \n",
      "792                   1.0               0.0              0.0   \n",
      "793                   0.0               0.0              0.0   \n",
      "794                   1.0               0.0              0.0   \n",
      "795                   0.0               0.0              1.0   \n",
      "796                   1.0               0.0              0.0   \n",
      "797                   0.0               1.0              0.0   \n",
      "798                   1.0               1.0              0.0   \n",
      "799                   0.0               0.0              0.0   \n",
      "800                   0.0               0.0              0.0   \n",
      "801                   0.0               0.0              0.0   \n",
      "802                   1.0               0.0              0.0   \n",
      "803                   1.0               0.0              0.0   \n",
      "\n",
      "     Coat Lenght_short  Sex_male  Sex_female  \n",
      "0                  1.0       0.0         1.0  \n",
      "1                  0.0       1.0         0.0  \n",
      "2                  0.0       1.0         0.0  \n",
      "3                  1.0       0.0         1.0  \n",
      "4                  1.0       0.0         1.0  \n",
      "5                  0.0       0.0         1.0  \n",
      "6                  1.0       1.0         0.0  \n",
      "7                  1.0       0.0         1.0  \n",
      "8                  1.0       1.0         0.0  \n",
      "9                  0.0       1.0         0.0  \n",
      "10                 0.0       1.0         0.0  \n",
      "11                 1.0       0.0         1.0  \n",
      "12                 0.0       1.0         0.0  \n",
      "13                 0.0       1.0         0.0  \n",
      "14                 1.0       1.0         0.0  \n",
      "15                 0.0       1.0         0.0  \n",
      "16                 0.0       0.0         1.0  \n",
      "17                 1.0       0.0         1.0  \n",
      "18                 1.0       1.0         0.0  \n",
      "19                 0.0       1.0         0.0  \n",
      "20                 0.0       1.0         0.0  \n",
      "21                 1.0       1.0         0.0  \n",
      "22                 0.0       0.0         1.0  \n",
      "23                 1.0       0.0         1.0  \n",
      "24                 1.0       1.0         0.0  \n",
      "25                 1.0       1.0         0.0  \n",
      "26                 1.0       0.0         1.0  \n",
      "27                 1.0       1.0         0.0  \n",
      "28                 1.0       1.0         0.0  \n",
      "29                 0.0       0.0         1.0  \n",
      "..                 ...       ...         ...  \n",
      "774                0.0       1.0         0.0  \n",
      "775                1.0       0.0         1.0  \n",
      "776                1.0       1.0         0.0  \n",
      "777                1.0       1.0         0.0  \n",
      "778                1.0       1.0         0.0  \n",
      "779                1.0       1.0         0.0  \n",
      "780                1.0       0.0         1.0  \n",
      "781                1.0       0.0         1.0  \n",
      "782                1.0       0.0         1.0  \n",
      "783                1.0       1.0         0.0  \n",
      "784                1.0       0.0         1.0  \n",
      "785                1.0       0.0         1.0  \n",
      "786                1.0       0.0         1.0  \n",
      "787                0.0       0.0         1.0  \n",
      "788                1.0       0.0         1.0  \n",
      "789                1.0       1.0         0.0  \n",
      "790                1.0       0.0         1.0  \n",
      "791                1.0       0.0         1.0  \n",
      "792                1.0       1.0         0.0  \n",
      "793                1.0       0.0         1.0  \n",
      "794                1.0       1.0         0.0  \n",
      "795                0.0       0.0         1.0  \n",
      "796                1.0       1.0         0.0  \n",
      "797                0.0       1.0         0.0  \n",
      "798                0.0       0.0         1.0  \n",
      "799                1.0       1.0         0.0  \n",
      "800                1.0       0.0         1.0  \n",
      "801                1.0       0.0         1.0  \n",
      "802                1.0       0.0         1.0  \n",
      "803                1.0       1.0         0.0  \n",
      "\n",
      "[804 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "print(modified_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x110110278>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x10fb742b0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1107930b8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1107ba748>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x1107e3da0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1107e3dd8>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x11083bb00>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x11086a160>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x1108927f0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1108bbe80>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1108ec550>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x110912be0>],\n",
       "       [<matplotlib.axes._subplots.AxesSubplot object at 0x1109442b0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x11096a940>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x110993fd0>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1109c46a0>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vizualizarea Datelor\n",
    "modified_dataset.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = modified_dataset[\"Breed Name\"]\n",
    "test = modified_dataset.drop('Breed Name', axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(test, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary(model, X, y):\n",
    "  \"\"\"\n",
    "    Use this to plot the decision boundary of a trained model.\n",
    "  \"\"\"\n",
    "  \n",
    "  xx, yy = np.mgrid[-5:5:.01, -5:5:.01]\n",
    "  grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "  probs = model.predict_proba(grid)[:, 1].reshape(xx.shape)\n",
    "  f, ax = plt.subplots(figsize=(8, 6))\n",
    "  contour = ax.contourf(xx, yy, probs, 25, cmap=\"RdBu\",\n",
    "                        vmin=0, vmax=1)\n",
    "  ax_c = f.colorbar(contour)\n",
    "  ax_c.set_label(\"$P(y = 1)$\")\n",
    "  ax_c.set_ticks([0, .25, .5, .75, 1])\n",
    "\n",
    "  ax.scatter(X[:,0], X[:, 1], c=y, s=50,\n",
    "             cmap=\"RdBu\", vmin=-.2, vmax=1.2,\n",
    "             edgecolor=\"white\", linewidth=1)\n",
    "\n",
    "  ax.set(aspect=\"equal\",\n",
    "         xlim=(-5, 5), ylim=(-5, 5),\n",
    "         xlabel=\"$X_1$\", ylabel=\"$X_2$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.9850746268656716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:459: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# testing Logistic Regression\n",
    "from sklearn.metrics import accuracy_score\n",
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "accuracy = accuracy_score(model.predict(x_test), y_test)\n",
    "print(LogisticRegression.__name__, accuracy)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# testing Random Forests\n",
    "model = RandomForestClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "accuracy = accuracy_score(model.predict(x_test), y_test)\n",
    "print(RandomForestClassifier.__name__, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier 0.9900497512437811\n"
     ]
    }
   ],
   "source": [
    "# testing KNeighborsClassifier\n",
    "model = KNeighborsClassifier(n_neighbors=2)\n",
    "model.fit(x_train, y_train)\n",
    "accuracy = accuracy_score(model.predict(x_test), y_test)\n",
    "print(KNeighborsClassifier.__name__, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Holteiu_N_Daniel_Ninel_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Weight(g)  Height(cm)  Longevity(yrs) Energy level Attention Needs  \\\n",
      "0    27412.4472     46.4779         12.7271          med            high   \n",
      "1    33302.6172         NaN         12.9844          low             med   \n",
      "2    19184.9322     57.7801         10.1529         high            high   \n",
      "3    26228.6536     45.6682         13.5366          low             med   \n",
      "4     7720.7755     20.1153         13.8247         high             med   \n",
      "5    20379.5337     57.5140         10.2833         high            high   \n",
      "6    21246.1613         NaN         11.4508         high            high   \n",
      "7    21491.1460     56.7838         12.8966         high            high   \n",
      "8    21740.7510         NaN         11.4410         high            high   \n",
      "9     6820.8519     33.5175         13.6113         high             med   \n",
      "10   23545.6745         NaN         13.1212          med            high   \n",
      "11   14489.3409     20.8370         13.5397         high             med   \n",
      "12   27870.3226     46.1721         13.0982          med             med   \n",
      "13    5781.6924         NaN         14.5575         high             med   \n",
      "14   18222.0316     56.9236         10.2664         high            high   \n",
      "15   14639.3281     20.5574         13.2471         high             med   \n",
      "16    5891.8975     33.7275         13.4918         high             med   \n",
      "17   22944.6667     56.8545         11.2131         high            high   \n",
      "18   20387.9993     57.0346         10.8801          med            high   \n",
      "19    6195.4468     33.3480         15.1374         high             med   \n",
      "20   19197.6377     56.7990          9.9128         high             med   \n",
      "21   22062.7100         NaN         11.6038         high            high   \n",
      "22    6772.6109     34.4892         14.9422         high             med   \n",
      "23   27069.5952     46.0445         13.5513         high            high   \n",
      "24    7085.7969     34.0145         14.2225         high             low   \n",
      "25   30371.2457     46.0058         12.0043          med             med   \n",
      "26    8070.9800         NaN         13.9047         high             low   \n",
      "27    5683.7821     34.3349         13.9714         high             med   \n",
      "28    8173.7912     21.5752         12.9213         high            high   \n",
      "29   21375.9899     57.0617         12.4133         high            high   \n",
      "..          ...         ...             ...          ...             ...   \n",
      "970  29717.5202     46.1089         12.9650          med            high   \n",
      "971   6471.2563     35.4692         13.8880         high             med   \n",
      "972   7428.3210     34.8833         14.3188         high             med   \n",
      "973  29947.5342     46.8357         11.9766          med            high   \n",
      "974  19832.2147     45.8950         13.2507          med            high   \n",
      "975  23605.4947     46.7785         13.1943          low            high   \n",
      "976   5386.3058     34.4775         14.8145         high             med   \n",
      "977   6592.6675     34.4870         13.3046         high             med   \n",
      "978  13574.4412     20.1083         13.7816         high             med   \n",
      "979   7164.9452     34.5533         14.2401         high             med   \n",
      "980  22012.6106     57.7233         11.6081         high            high   \n",
      "981   8847.6432     20.8950         13.5220         high             med   \n",
      "982   5841.9292         NaN         13.3790          med             med   \n",
      "983  20652.8986     56.8116         12.5771          med            high   \n",
      "984  23348.2792     46.5524         12.4119          med            high   \n",
      "985   7187.5568     21.4954         13.3620         high            high   \n",
      "986  10361.1677     20.2664         11.9504         high             med   \n",
      "987   5008.3757     33.1474         13.3220         high            high   \n",
      "988   6613.5174     20.2383         12.8570         high             med   \n",
      "989  21328.1791     57.3835         11.5995         high            high   \n",
      "990   8992.4889     21.2831         12.1729         high             med   \n",
      "991  20368.0889     56.8945         11.5040         high            high   \n",
      "992  18205.4872     56.5899         10.9126         high             med   \n",
      "993   4771.1665     20.7992         12.4886         high            high   \n",
      "994   6850.8759     33.5483         13.6792         high            high   \n",
      "995  27774.3222         NaN         13.6471          med            high   \n",
      "996   7918.2192     34.0478         13.8639         high             low   \n",
      "997  13340.7933     21.5531         11.9293         high             med   \n",
      "998  20505.2008         NaN         11.7436         high            high   \n",
      "999   6642.2769     33.3306         13.7579         high             med   \n",
      "\n",
      "    Coat Lenght     Sex  \n",
      "0         short    male  \n",
      "1         short  female  \n",
      "2           med  female  \n",
      "3           med  female  \n",
      "4         short    male  \n",
      "5         short    male  \n",
      "6           med    male  \n",
      "7           med    male  \n",
      "8         short  female  \n",
      "9         short  female  \n",
      "10        short    male  \n",
      "11        short    male  \n",
      "12        short  female  \n",
      "13        short  female  \n",
      "14          med  female  \n",
      "15          med  female  \n",
      "16        short    male  \n",
      "17         long  female  \n",
      "18          med  female  \n",
      "19        short  female  \n",
      "20          med  female  \n",
      "21          med  female  \n",
      "22          med    male  \n",
      "23        short    male  \n",
      "24        short  female  \n",
      "25          med  female  \n",
      "26        short    male  \n",
      "27          med  female  \n",
      "28        short  female  \n",
      "29          med    male  \n",
      "..          ...     ...  \n",
      "970       short  female  \n",
      "971       short  female  \n",
      "972       short  female  \n",
      "973       short    male  \n",
      "974       short    male  \n",
      "975       short    male  \n",
      "976       short  female  \n",
      "977       short    male  \n",
      "978       short    male  \n",
      "979       short    male  \n",
      "980         med    male  \n",
      "981       short    male  \n",
      "982       short    male  \n",
      "983       short  female  \n",
      "984       short    male  \n",
      "985       short    male  \n",
      "986       short  female  \n",
      "987       short    male  \n",
      "988       short  female  \n",
      "989         med    male  \n",
      "990       short  female  \n",
      "991        long  female  \n",
      "992        long    male  \n",
      "993       short  female  \n",
      "994       short    male  \n",
      "995       short    male  \n",
      "996       short    male  \n",
      "997       short    male  \n",
      "998         med  female  \n",
      "999       short  female  \n",
      "\n",
      "[1000 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# get rid of Breed Name\n",
    "modified_dataset = dataset\n",
    "modified_dataset = modified_dataset.drop('Breed Name', axis=1)\n",
    "modified_dataset = modified_dataset.drop('Owner Name', axis=1)\n",
    "print(modified_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight(g)            0\n",
      "Height(cm)         196\n",
      "Longevity(yrs)       0\n",
      "Energy level         0\n",
      "Attention Needs      0\n",
      "Coat Lenght          0\n",
      "Sex                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Handling Missing Data\n",
    "print(modified_dataset.isnull().sum())\n",
    "modified_dataset = modified_dataset.dropna() # drop missing data\n",
    "modified_dataset = modified_dataset.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Handling Categorical Data\n",
    "# The Categorical Data is handled using One Hot Encoder.\n",
    "categorical_columns = [\"Energy level\", \"Attention Needs\", \"Coat Lenght\", \"Sex\"]\n",
    "for column in categorical_columns:\n",
    "    label_encoder = LabelEncoder()\n",
    "    ohe_encoder = OneHotEncoder()\n",
    "    unique_columns = set(dataset[column].tolist())\n",
    "    unique_columns = {key: value for key, value in zip(range(len(unique_columns)), unique_columns)}\n",
    "    modified_dataset[column + \"_encoded\"] = label_encoder.fit_transform(modified_dataset[column])\n",
    "    aux = ohe_encoder.fit_transform(modified_dataset[column + \"_encoded\"].values.reshape(-1, 1)).toarray()\n",
    "    aux = pd.DataFrame(aux, columns=[column + \"_\" + unique_columns.get(i) for i in range(aux.shape[1])])\n",
    "    modified_dataset = pd.concat([modified_dataset, aux], axis=1)\n",
    "    modified_dataset = modified_dataset.drop(column, axis=1)\n",
    "    modified_dataset = modified_dataset.drop(column + \"_encoded\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization (Just for Weight(g) and Height(cm)). I am using Min Max Normalizer\n",
    "# (X - min(X)) / (max(X) - min(X))\n",
    "modified_dataset[\"Weight(g)\"] = (modified_dataset[\"Weight(g)\"] - modified_dataset[\"Weight(g)\"].min()) / (modified_dataset[\"Weight(g)\"].max() - modified_dataset[\"Weight(g)\"].min())\n",
    "modified_dataset[\"Height(cm)\"] = (modified_dataset[\"Height(cm)\"] - modified_dataset[\"Height(cm)\"].min()) / (modified_dataset[\"Height(cm)\"].max() - modified_dataset[\"Height(cm)\"].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight(g)</th>\n",
       "      <th>Height(cm)</th>\n",
       "      <th>Longevity(yrs)</th>\n",
       "      <th>Energy level_low</th>\n",
       "      <th>Energy level_med</th>\n",
       "      <th>Energy level_high</th>\n",
       "      <th>Attention Needs_low</th>\n",
       "      <th>Attention Needs_med</th>\n",
       "      <th>Attention Needs_high</th>\n",
       "      <th>Coat Lenght_long</th>\n",
       "      <th>Coat Lenght_med</th>\n",
       "      <th>Coat Lenght_short</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Sex_female</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.759598</td>\n",
       "      <td>0.684992</td>\n",
       "      <td>12.7271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.529946</td>\n",
       "      <td>0.971062</td>\n",
       "      <td>10.1529</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.726555</td>\n",
       "      <td>0.664498</td>\n",
       "      <td>13.5366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.209950</td>\n",
       "      <td>0.017728</td>\n",
       "      <td>13.8247</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.563290</td>\n",
       "      <td>0.964327</td>\n",
       "      <td>10.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.594318</td>\n",
       "      <td>0.945845</td>\n",
       "      <td>12.8966</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.184831</td>\n",
       "      <td>0.356951</td>\n",
       "      <td>13.6113</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.398879</td>\n",
       "      <td>0.035995</td>\n",
       "      <td>13.5397</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.772379</td>\n",
       "      <td>0.677252</td>\n",
       "      <td>13.0982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.503069</td>\n",
       "      <td>0.949383</td>\n",
       "      <td>10.2664</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.403066</td>\n",
       "      <td>0.028918</td>\n",
       "      <td>13.2471</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.158901</td>\n",
       "      <td>0.362266</td>\n",
       "      <td>13.4918</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.634890</td>\n",
       "      <td>0.947634</td>\n",
       "      <td>11.2131</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.563527</td>\n",
       "      <td>0.952193</td>\n",
       "      <td>10.8801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.167374</td>\n",
       "      <td>0.352661</td>\n",
       "      <td>15.1374</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.530300</td>\n",
       "      <td>0.946229</td>\n",
       "      <td>9.9128</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.183484</td>\n",
       "      <td>0.381546</td>\n",
       "      <td>14.9422</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.750028</td>\n",
       "      <td>0.674022</td>\n",
       "      <td>13.5513</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.192226</td>\n",
       "      <td>0.369531</td>\n",
       "      <td>14.2225</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.842186</td>\n",
       "      <td>0.673043</td>\n",
       "      <td>12.0043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.153092</td>\n",
       "      <td>0.377640</td>\n",
       "      <td>13.9714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.222595</td>\n",
       "      <td>0.054679</td>\n",
       "      <td>12.9213</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.591104</td>\n",
       "      <td>0.952878</td>\n",
       "      <td>12.4133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.172888</td>\n",
       "      <td>0.383176</td>\n",
       "      <td>13.7513</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.111574</td>\n",
       "      <td>0.023813</td>\n",
       "      <td>12.7318</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.211218</td>\n",
       "      <td>0.370677</td>\n",
       "      <td>14.5031</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.274677</td>\n",
       "      <td>0.044859</td>\n",
       "      <td>12.0646</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.794510</td>\n",
       "      <td>0.671810</td>\n",
       "      <td>13.3095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.172960</td>\n",
       "      <td>0.375656</td>\n",
       "      <td>14.2620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.559655</td>\n",
       "      <td>0.957290</td>\n",
       "      <td>11.1763</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>0.548391</td>\n",
       "      <td>0.966817</td>\n",
       "      <td>10.3522</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>0.665537</td>\n",
       "      <td>0.672820</td>\n",
       "      <td>12.1207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>0.821460</td>\n",
       "      <td>0.670385</td>\n",
       "      <td>11.6131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>0.823939</td>\n",
       "      <td>0.675652</td>\n",
       "      <td>12.9650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>0.175073</td>\n",
       "      <td>0.406351</td>\n",
       "      <td>13.8880</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>0.201787</td>\n",
       "      <td>0.391521</td>\n",
       "      <td>14.3188</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>0.830359</td>\n",
       "      <td>0.694048</td>\n",
       "      <td>11.9766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>0.548013</td>\n",
       "      <td>0.670238</td>\n",
       "      <td>13.2507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>0.653336</td>\n",
       "      <td>0.692600</td>\n",
       "      <td>13.1943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>0.144789</td>\n",
       "      <td>0.381250</td>\n",
       "      <td>14.8145</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>0.178462</td>\n",
       "      <td>0.381490</td>\n",
       "      <td>13.3046</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>785</th>\n",
       "      <td>0.373342</td>\n",
       "      <td>0.017551</td>\n",
       "      <td>13.7816</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>0.194435</td>\n",
       "      <td>0.383168</td>\n",
       "      <td>14.2401</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>0.608874</td>\n",
       "      <td>0.969624</td>\n",
       "      <td>11.6081</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>0.241404</td>\n",
       "      <td>0.037463</td>\n",
       "      <td>13.5220</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>0.570921</td>\n",
       "      <td>0.946548</td>\n",
       "      <td>12.5771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>0.646156</td>\n",
       "      <td>0.686878</td>\n",
       "      <td>12.4119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>0.195067</td>\n",
       "      <td>0.052660</td>\n",
       "      <td>13.3620</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>792</th>\n",
       "      <td>0.283651</td>\n",
       "      <td>0.021552</td>\n",
       "      <td>11.9504</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>793</th>\n",
       "      <td>0.134240</td>\n",
       "      <td>0.347583</td>\n",
       "      <td>13.3220</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>0.179044</td>\n",
       "      <td>0.020841</td>\n",
       "      <td>12.8570</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>0.589770</td>\n",
       "      <td>0.961024</td>\n",
       "      <td>11.5995</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>0.245447</td>\n",
       "      <td>0.047286</td>\n",
       "      <td>12.1729</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>0.562971</td>\n",
       "      <td>0.948646</td>\n",
       "      <td>11.5040</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>0.502607</td>\n",
       "      <td>0.940937</td>\n",
       "      <td>10.9126</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>0.127619</td>\n",
       "      <td>0.035038</td>\n",
       "      <td>12.4886</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>0.185669</td>\n",
       "      <td>0.357731</td>\n",
       "      <td>13.6792</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>0.215461</td>\n",
       "      <td>0.370373</td>\n",
       "      <td>13.8639</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>0.366820</td>\n",
       "      <td>0.054120</td>\n",
       "      <td>11.9293</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>0.179846</td>\n",
       "      <td>0.352220</td>\n",
       "      <td>13.7579</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>804 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Weight(g)  Height(cm)  Longevity(yrs)  Energy level_low  \\\n",
       "0     0.759598    0.684992         12.7271               0.0   \n",
       "1     0.529946    0.971062         10.1529               1.0   \n",
       "2     0.726555    0.664498         13.5366               0.0   \n",
       "3     0.209950    0.017728         13.8247               1.0   \n",
       "4     0.563290    0.964327         10.2833               1.0   \n",
       "5     0.594318    0.945845         12.8966               1.0   \n",
       "6     0.184831    0.356951         13.6113               1.0   \n",
       "7     0.398879    0.035995         13.5397               1.0   \n",
       "8     0.772379    0.677252         13.0982               0.0   \n",
       "9     0.503069    0.949383         10.2664               1.0   \n",
       "10    0.403066    0.028918         13.2471               1.0   \n",
       "11    0.158901    0.362266         13.4918               1.0   \n",
       "12    0.634890    0.947634         11.2131               1.0   \n",
       "13    0.563527    0.952193         10.8801               0.0   \n",
       "14    0.167374    0.352661         15.1374               1.0   \n",
       "15    0.530300    0.946229          9.9128               1.0   \n",
       "16    0.183484    0.381546         14.9422               1.0   \n",
       "17    0.750028    0.674022         13.5513               1.0   \n",
       "18    0.192226    0.369531         14.2225               1.0   \n",
       "19    0.842186    0.673043         12.0043               0.0   \n",
       "20    0.153092    0.377640         13.9714               1.0   \n",
       "21    0.222595    0.054679         12.9213               1.0   \n",
       "22    0.591104    0.952878         12.4133               1.0   \n",
       "23    0.172888    0.383176         13.7513               1.0   \n",
       "24    0.111574    0.023813         12.7318               1.0   \n",
       "25    0.211218    0.370677         14.5031               1.0   \n",
       "26    0.274677    0.044859         12.0646               1.0   \n",
       "27    0.794510    0.671810         13.3095               0.0   \n",
       "28    0.172960    0.375656         14.2620               0.0   \n",
       "29    0.559655    0.957290         11.1763               1.0   \n",
       "..         ...         ...             ...               ...   \n",
       "774   0.548391    0.966817         10.3522               1.0   \n",
       "775   0.665537    0.672820         12.1207               0.0   \n",
       "776   0.821460    0.670385         11.6131               0.0   \n",
       "777   0.823939    0.675652         12.9650               0.0   \n",
       "778   0.175073    0.406351         13.8880               1.0   \n",
       "779   0.201787    0.391521         14.3188               1.0   \n",
       "780   0.830359    0.694048         11.9766               0.0   \n",
       "781   0.548013    0.670238         13.2507               0.0   \n",
       "782   0.653336    0.692600         13.1943               0.0   \n",
       "783   0.144789    0.381250         14.8145               1.0   \n",
       "784   0.178462    0.381490         13.3046               1.0   \n",
       "785   0.373342    0.017551         13.7816               1.0   \n",
       "786   0.194435    0.383168         14.2401               1.0   \n",
       "787   0.608874    0.969624         11.6081               1.0   \n",
       "788   0.241404    0.037463         13.5220               1.0   \n",
       "789   0.570921    0.946548         12.5771               0.0   \n",
       "790   0.646156    0.686878         12.4119               0.0   \n",
       "791   0.195067    0.052660         13.3620               1.0   \n",
       "792   0.283651    0.021552         11.9504               1.0   \n",
       "793   0.134240    0.347583         13.3220               1.0   \n",
       "794   0.179044    0.020841         12.8570               1.0   \n",
       "795   0.589770    0.961024         11.5995               1.0   \n",
       "796   0.245447    0.047286         12.1729               1.0   \n",
       "797   0.562971    0.948646         11.5040               1.0   \n",
       "798   0.502607    0.940937         10.9126               1.0   \n",
       "799   0.127619    0.035038         12.4886               1.0   \n",
       "800   0.185669    0.357731         13.6792               1.0   \n",
       "801   0.215461    0.370373         13.8639               1.0   \n",
       "802   0.366820    0.054120         11.9293               1.0   \n",
       "803   0.179846    0.352220         13.7579               1.0   \n",
       "\n",
       "     Energy level_med  Energy level_high  Attention Needs_low  \\\n",
       "0                 0.0                1.0                  1.0   \n",
       "1                 0.0                0.0                  1.0   \n",
       "2                 1.0                0.0                  0.0   \n",
       "3                 0.0                0.0                  0.0   \n",
       "4                 0.0                0.0                  1.0   \n",
       "5                 0.0                0.0                  1.0   \n",
       "6                 0.0                0.0                  0.0   \n",
       "7                 0.0                0.0                  0.0   \n",
       "8                 0.0                1.0                  0.0   \n",
       "9                 0.0                0.0                  1.0   \n",
       "10                0.0                0.0                  0.0   \n",
       "11                0.0                0.0                  0.0   \n",
       "12                0.0                0.0                  1.0   \n",
       "13                0.0                1.0                  1.0   \n",
       "14                0.0                0.0                  0.0   \n",
       "15                0.0                0.0                  0.0   \n",
       "16                0.0                0.0                  0.0   \n",
       "17                0.0                0.0                  1.0   \n",
       "18                0.0                0.0                  0.0   \n",
       "19                0.0                1.0                  0.0   \n",
       "20                0.0                0.0                  0.0   \n",
       "21                0.0                0.0                  1.0   \n",
       "22                0.0                0.0                  1.0   \n",
       "23                0.0                0.0                  0.0   \n",
       "24                0.0                0.0                  0.0   \n",
       "25                0.0                0.0                  0.0   \n",
       "26                0.0                0.0                  0.0   \n",
       "27                0.0                1.0                  1.0   \n",
       "28                0.0                1.0                  0.0   \n",
       "29                0.0                0.0                  1.0   \n",
       "..                ...                ...                  ...   \n",
       "774               0.0                0.0                  1.0   \n",
       "775               1.0                0.0                  1.0   \n",
       "776               0.0                1.0                  1.0   \n",
       "777               0.0                1.0                  1.0   \n",
       "778               0.0                0.0                  0.0   \n",
       "779               0.0                0.0                  0.0   \n",
       "780               0.0                1.0                  1.0   \n",
       "781               0.0                1.0                  1.0   \n",
       "782               1.0                0.0                  1.0   \n",
       "783               0.0                0.0                  0.0   \n",
       "784               0.0                0.0                  0.0   \n",
       "785               0.0                0.0                  0.0   \n",
       "786               0.0                0.0                  0.0   \n",
       "787               0.0                0.0                  1.0   \n",
       "788               0.0                0.0                  0.0   \n",
       "789               0.0                1.0                  1.0   \n",
       "790               0.0                1.0                  1.0   \n",
       "791               0.0                0.0                  1.0   \n",
       "792               0.0                0.0                  0.0   \n",
       "793               0.0                0.0                  1.0   \n",
       "794               0.0                0.0                  0.0   \n",
       "795               0.0                0.0                  1.0   \n",
       "796               0.0                0.0                  0.0   \n",
       "797               0.0                0.0                  1.0   \n",
       "798               0.0                0.0                  0.0   \n",
       "799               0.0                0.0                  1.0   \n",
       "800               0.0                0.0                  1.0   \n",
       "801               0.0                0.0                  0.0   \n",
       "802               0.0                0.0                  0.0   \n",
       "803               0.0                0.0                  0.0   \n",
       "\n",
       "     Attention Needs_med  Attention Needs_high  Coat Lenght_long  \\\n",
       "0                    0.0                   0.0               0.0   \n",
       "1                    0.0                   0.0               0.0   \n",
       "2                    0.0                   1.0               0.0   \n",
       "3                    0.0                   1.0               0.0   \n",
       "4                    0.0                   0.0               0.0   \n",
       "5                    0.0                   0.0               0.0   \n",
       "6                    0.0                   1.0               0.0   \n",
       "7                    0.0                   1.0               0.0   \n",
       "8                    0.0                   1.0               0.0   \n",
       "9                    0.0                   0.0               0.0   \n",
       "10                   0.0                   1.0               0.0   \n",
       "11                   0.0                   1.0               0.0   \n",
       "12                   0.0                   0.0               1.0   \n",
       "13                   0.0                   0.0               0.0   \n",
       "14                   0.0                   1.0               0.0   \n",
       "15                   0.0                   1.0               0.0   \n",
       "16                   0.0                   1.0               0.0   \n",
       "17                   0.0                   0.0               0.0   \n",
       "18                   1.0                   0.0               0.0   \n",
       "19                   0.0                   1.0               0.0   \n",
       "20                   0.0                   1.0               0.0   \n",
       "21                   0.0                   0.0               0.0   \n",
       "22                   0.0                   0.0               0.0   \n",
       "23                   0.0                   1.0               0.0   \n",
       "24                   0.0                   1.0               0.0   \n",
       "25                   0.0                   1.0               0.0   \n",
       "26                   0.0                   1.0               0.0   \n",
       "27                   0.0                   0.0               0.0   \n",
       "28                   0.0                   1.0               0.0   \n",
       "29                   0.0                   0.0               0.0   \n",
       "..                   ...                   ...               ...   \n",
       "774                  0.0                   0.0               0.0   \n",
       "775                  0.0                   0.0               0.0   \n",
       "776                  0.0                   0.0               0.0   \n",
       "777                  0.0                   0.0               0.0   \n",
       "778                  0.0                   1.0               0.0   \n",
       "779                  0.0                   1.0               0.0   \n",
       "780                  0.0                   0.0               0.0   \n",
       "781                  0.0                   0.0               0.0   \n",
       "782                  0.0                   0.0               0.0   \n",
       "783                  0.0                   1.0               0.0   \n",
       "784                  0.0                   1.0               0.0   \n",
       "785                  0.0                   1.0               0.0   \n",
       "786                  0.0                   1.0               0.0   \n",
       "787                  0.0                   0.0               0.0   \n",
       "788                  0.0                   1.0               0.0   \n",
       "789                  0.0                   0.0               0.0   \n",
       "790                  0.0                   0.0               0.0   \n",
       "791                  0.0                   0.0               0.0   \n",
       "792                  0.0                   1.0               0.0   \n",
       "793                  0.0                   0.0               0.0   \n",
       "794                  0.0                   1.0               0.0   \n",
       "795                  0.0                   0.0               0.0   \n",
       "796                  0.0                   1.0               0.0   \n",
       "797                  0.0                   0.0               1.0   \n",
       "798                  0.0                   1.0               1.0   \n",
       "799                  0.0                   0.0               0.0   \n",
       "800                  0.0                   0.0               0.0   \n",
       "801                  1.0                   0.0               0.0   \n",
       "802                  0.0                   1.0               0.0   \n",
       "803                  0.0                   1.0               0.0   \n",
       "\n",
       "     Coat Lenght_med  Coat Lenght_short  Sex_male  Sex_female  \n",
       "0                0.0                1.0       0.0         1.0  \n",
       "1                1.0                0.0       1.0         0.0  \n",
       "2                1.0                0.0       1.0         0.0  \n",
       "3                0.0                1.0       0.0         1.0  \n",
       "4                0.0                1.0       0.0         1.0  \n",
       "5                1.0                0.0       0.0         1.0  \n",
       "6                0.0                1.0       1.0         0.0  \n",
       "7                0.0                1.0       0.0         1.0  \n",
       "8                0.0                1.0       1.0         0.0  \n",
       "9                1.0                0.0       1.0         0.0  \n",
       "10               1.0                0.0       1.0         0.0  \n",
       "11               0.0                1.0       0.0         1.0  \n",
       "12               0.0                0.0       1.0         0.0  \n",
       "13               1.0                0.0       1.0         0.0  \n",
       "14               0.0                1.0       1.0         0.0  \n",
       "15               1.0                0.0       1.0         0.0  \n",
       "16               1.0                0.0       0.0         1.0  \n",
       "17               0.0                1.0       0.0         1.0  \n",
       "18               0.0                1.0       1.0         0.0  \n",
       "19               1.0                0.0       1.0         0.0  \n",
       "20               1.0                0.0       1.0         0.0  \n",
       "21               0.0                1.0       1.0         0.0  \n",
       "22               1.0                0.0       0.0         1.0  \n",
       "23               0.0                1.0       0.0         1.0  \n",
       "24               0.0                1.0       1.0         0.0  \n",
       "25               0.0                1.0       1.0         0.0  \n",
       "26               0.0                1.0       0.0         1.0  \n",
       "27               0.0                1.0       1.0         0.0  \n",
       "28               0.0                1.0       1.0         0.0  \n",
       "29               1.0                0.0       0.0         1.0  \n",
       "..               ...                ...       ...         ...  \n",
       "774              1.0                0.0       1.0         0.0  \n",
       "775              0.0                1.0       0.0         1.0  \n",
       "776              0.0                1.0       1.0         0.0  \n",
       "777              0.0                1.0       1.0         0.0  \n",
       "778              0.0                1.0       1.0         0.0  \n",
       "779              0.0                1.0       1.0         0.0  \n",
       "780              0.0                1.0       0.0         1.0  \n",
       "781              0.0                1.0       0.0         1.0  \n",
       "782              0.0                1.0       0.0         1.0  \n",
       "783              0.0                1.0       1.0         0.0  \n",
       "784              0.0                1.0       0.0         1.0  \n",
       "785              0.0                1.0       0.0         1.0  \n",
       "786              0.0                1.0       0.0         1.0  \n",
       "787              1.0                0.0       0.0         1.0  \n",
       "788              0.0                1.0       0.0         1.0  \n",
       "789              0.0                1.0       1.0         0.0  \n",
       "790              0.0                1.0       0.0         1.0  \n",
       "791              0.0                1.0       0.0         1.0  \n",
       "792              0.0                1.0       1.0         0.0  \n",
       "793              0.0                1.0       0.0         1.0  \n",
       "794              0.0                1.0       1.0         0.0  \n",
       "795              1.0                0.0       0.0         1.0  \n",
       "796              0.0                1.0       1.0         0.0  \n",
       "797              0.0                0.0       1.0         0.0  \n",
       "798              0.0                0.0       0.0         1.0  \n",
       "799              0.0                1.0       1.0         0.0  \n",
       "800              0.0                1.0       0.0         1.0  \n",
       "801              0.0                1.0       0.0         1.0  \n",
       "802              0.0                1.0       0.0         1.0  \n",
       "803              0.0                1.0       1.0         0.0  \n",
       "\n",
       "[804 rows x 14 columns]"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = modified_dataset[\"Longevity(yrs)\"]\n",
    "test = modified_dataset.drop('Longevity(yrs)', axis=1)\n",
    "x_train, x_test, y_train, y_test = train_test_split(test, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "predictions = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test =  11.292  y_predicted =  11.75390625  Difference =  0.4619062500000002\n",
      "y_test =  13.4986  y_predicted =  13.2890625  Difference =  0.2095374999999997\n",
      "y_test =  12.7693  y_predicted =  12.87109375  Difference =  0.10179375000000057\n",
      "y_test =  13.4918  y_predicted =  13.57421875  Difference =  0.08241875000000043\n",
      "y_test =  11.4944  y_predicted =  11.859375  Difference =  0.3649749999999994\n",
      "y_test =  12.6665  y_predicted =  13.59375  Difference =  0.9272500000000008\n",
      "y_test =  10.9615  y_predicted =  11.5390625  Difference =  0.5775625000000009\n",
      "y_test =  11.6686  y_predicted =  11.6796875  Difference =  0.011087500000000361\n",
      "y_test =  14.1349  y_predicted =  13.5234375  Difference =  0.6114625\n",
      "y_test =  11.6081  y_predicted =  11.65234375  Difference =  0.04424374999999969\n",
      "y_test =  14.6025  y_predicted =  13.49609375  Difference =  1.1064062499999991\n",
      "y_test =  12.8483  y_predicted =  13.078125  Difference =  0.22982499999999995\n",
      "y_test =  13.6411  y_predicted =  12.7734375  Difference =  0.8676624999999998\n",
      "y_test =  14.9366  y_predicted =  13.5078125  Difference =  1.4287875000000003\n",
      "y_test =  11.7551  y_predicted =  11.7734375  Difference =  0.01833749999999945\n",
      "y_test =  12.8071  y_predicted =  13.0859375  Difference =  0.27883749999999985\n",
      "y_test =  13.5216  y_predicted =  13.234375  Difference =  0.2872249999999994\n",
      "y_test =  12.8758  y_predicted =  12.87890625  Difference =  0.003106250000000088\n",
      "y_test =  11.940999999999999  y_predicted =  11.65234375  Difference =  0.28865624999999895\n",
      "y_test =  12.6712  y_predicted =  13.42578125  Difference =  0.7545812499999993\n",
      "y_test =  13.1599  y_predicted =  12.2265625  Difference =  0.9333375000000004\n",
      "y_test =  13.052  y_predicted =  11.85546875  Difference =  1.1965312499999996\n",
      "y_test =  10.5691  y_predicted =  12.875  Difference =  2.3058999999999994\n",
      "y_test =  13.4958  y_predicted =  13.359375  Difference =  0.13642499999999913\n",
      "y_test =  13.9261  y_predicted =  13.0546875  Difference =  0.8714124999999999\n",
      "y_test =  12.6416  y_predicted =  13.2265625  Difference =  0.5849624999999996\n",
      "y_test =  13.6515  y_predicted =  13.19140625  Difference =  0.4600937500000004\n",
      "y_test =  11.5991  y_predicted =  11.6796875  Difference =  0.08058750000000003\n",
      "y_test =  12.3408  y_predicted =  11.6640625  Difference =  0.6767374999999998\n",
      "y_test =  15.5293  y_predicted =  14.09765625  Difference =  1.4316437499999992\n",
      "y_test =  11.8392  y_predicted =  12.3828125  Difference =  0.5436125\n",
      "y_test =  13.3924  y_predicted =  13.49609375  Difference =  0.1036937499999997\n",
      "y_test =  13.1861  y_predicted =  12.9453125  Difference =  0.2407874999999997\n",
      "y_test =  11.1192  y_predicted =  11.6640625  Difference =  0.5448625000000007\n",
      "y_test =  13.6979  y_predicted =  13.6328125  Difference =  0.06508750000000063\n",
      "y_test =  13.1229  y_predicted =  13.5234375  Difference =  0.40053750000000043\n",
      "y_test =  12.6209  y_predicted =  14.125  Difference =  1.5040999999999993\n",
      "y_test =  13.542  y_predicted =  13.546875  Difference =  0.004875000000000185\n",
      "y_test =  13.565  y_predicted =  12.984375  Difference =  0.5806249999999995\n",
      "y_test =  12.9184  y_predicted =  13.41796875  Difference =  0.4995687499999999\n",
      "y_test =  12.5828  y_predicted =  12.37890625  Difference =  0.20389375000000065\n",
      "y_test =  10.2563  y_predicted =  11.76171875  Difference =  1.5054187500000005\n",
      "y_test =  13.6086  y_predicted =  13.4140625  Difference =  0.19453749999999914\n",
      "y_test =  12.8906  y_predicted =  13.39453125  Difference =  0.5039312500000008\n",
      "y_test =  11.3111  y_predicted =  11.60546875  Difference =  0.2943687500000003\n",
      "y_test =  12.9525  y_predicted =  12.98046875  Difference =  0.02796874999999943\n",
      "y_test =  14.3755  y_predicted =  13.546875  Difference =  0.8286250000000006\n",
      "y_test =  12.970999999999998  y_predicted =  12.41015625  Difference =  0.5608437499999983\n",
      "y_test =  12.4117  y_predicted =  13.375  Difference =  0.9633000000000003\n",
      "y_test =  11.4476  y_predicted =  11.734375  Difference =  0.28677500000000045\n",
      "y_test =  12.8487  y_predicted =  12.62109375  Difference =  0.22760624999999912\n",
      "y_test =  13.9147  y_predicted =  13.52734375  Difference =  0.38735624999999985\n",
      "y_test =  11.2268  y_predicted =  12.08203125  Difference =  0.8552312499999992\n",
      "y_test =  12.2058  y_predicted =  13.26953125  Difference =  1.06373125\n",
      "y_test =  12.9809  y_predicted =  11.77734375  Difference =  1.20355625\n",
      "y_test =  12.7393  y_predicted =  13.0703125  Difference =  0.33101249999999993\n",
      "y_test =  13.299000000000001  y_predicted =  12.58203125  Difference =  0.7169687500000013\n",
      "y_test =  10.2975  y_predicted =  11.76953125  Difference =  1.4720312500000006\n",
      "y_test =  13.8045  y_predicted =  13.5703125  Difference =  0.23418750000000088\n",
      "y_test =  13.6104  y_predicted =  12.7265625  Difference =  0.8838375000000003\n",
      "y_test =  13.0825  y_predicted =  13.0703125  Difference =  0.012187499999999574\n",
      "y_test =  12.7611  y_predicted =  12.2890625  Difference =  0.4720375000000008\n",
      "y_test =  10.7413  y_predicted =  11.7265625  Difference =  0.9852624999999993\n",
      "y_test =  11.8702  y_predicted =  11.80078125  Difference =  0.06941875000000053\n",
      "y_test =  14.0943  y_predicted =  13.25390625  Difference =  0.8403937500000005\n",
      "y_test =  14.8653  y_predicted =  13.4296875  Difference =  1.4356124999999995\n",
      "y_test =  14.0121  y_predicted =  13.59375  Difference =  0.4183500000000002\n",
      "y_test =  13.9951  y_predicted =  13.52734375  Difference =  0.46775625000000076\n",
      "y_test =  14.5059  y_predicted =  12.76171875  Difference =  1.7441812500000005\n",
      "y_test =  12.2464  y_predicted =  11.65234375  Difference =  0.5940562499999995\n",
      "y_test =  13.1786  y_predicted =  12.8203125  Difference =  0.3582874999999994\n",
      "y_test =  13.0168  y_predicted =  13.52734375  Difference =  0.5105437500000001\n",
      "y_test =  12.7576  y_predicted =  13.01171875  Difference =  0.25411874999999995\n",
      "y_test =  13.1266  y_predicted =  13.203125  Difference =  0.07652500000000018\n",
      "y_test =  10.9064  y_predicted =  11.72265625  Difference =  0.8162562500000003\n",
      "y_test =  14.2401  y_predicted =  13.50390625  Difference =  0.73619375\n",
      "y_test =  13.4119  y_predicted =  12.93359375  Difference =  0.47830624999999927\n",
      "y_test =  12.3242  y_predicted =  13.8203125  Difference =  1.4961125000000006\n",
      "y_test =  11.9966  y_predicted =  11.671875  Difference =  0.3247250000000008\n",
      "y_test =  12.3328  y_predicted =  11.984375  Difference =  0.34842500000000065\n",
      "y_test =  14.6127  y_predicted =  13.55859375  Difference =  1.0541062500000002\n",
      "y_test =  11.354000000000001  y_predicted =  11.69921875  Difference =  0.345218749999999\n",
      "y_test =  12.9223  y_predicted =  13.47265625  Difference =  0.5503562500000001\n",
      "y_test =  13.522  y_predicted =  13.47265625  Difference =  0.04934375000000024\n",
      "y_test =  12.7199  y_predicted =  12.5234375  Difference =  0.19646250000000087\n",
      "y_test =  11.3047  y_predicted =  12.4453125  Difference =  1.1406124999999996\n",
      "y_test =  10.745  y_predicted =  11.6953125  Difference =  0.9503125000000008\n",
      "y_test =  13.6558  y_predicted =  12.00390625  Difference =  1.6518937499999993\n",
      "y_test =  13.8  y_predicted =  13.30078125  Difference =  0.4992187500000007\n",
      "y_test =  14.1834  y_predicted =  13.48046875  Difference =  0.7029312500000007\n",
      "y_test =  12.4246  y_predicted =  13.296875  Difference =  0.8722750000000001\n",
      "y_test =  13.819  y_predicted =  13.5390625  Difference =  0.27993750000000084\n",
      "y_test =  12.2231  y_predicted =  11.78515625  Difference =  0.4379437500000005\n",
      "y_test =  13.607999999999999  y_predicted =  12.703125  Difference =  0.9048749999999988\n",
      "y_test =  13.0906  y_predicted =  13.4921875  Difference =  0.40158749999999976\n",
      "y_test =  12.0993  y_predicted =  12.73828125  Difference =  0.6389812500000005\n",
      "y_test =  13.3351  y_predicted =  12.734375  Difference =  0.6007250000000006\n",
      "y_test =  12.8426  y_predicted =  13.4921875  Difference =  0.6495875000000009\n",
      "y_test =  14.262  y_predicted =  14.1484375  Difference =  0.11356250000000045\n",
      "y_test =  12.9795  y_predicted =  13.0234375  Difference =  0.043937500000000185\n",
      "y_test =  11.9029  y_predicted =  14.1640625  Difference =  2.2611624999999993\n",
      "y_test =  12.2291  y_predicted =  13.2578125  Difference =  1.0287124999999993\n",
      "y_test =  14.4103  y_predicted =  13.48828125  Difference =  0.9220187499999994\n",
      "y_test =  12.5615  y_predicted =  13.15625  Difference =  0.5947499999999994\n",
      "y_test =  12.2045  y_predicted =  13.015625  Difference =  0.8111250000000005\n",
      "y_test =  13.3267  y_predicted =  13.46875  Difference =  0.14204999999999934\n",
      "y_test =  14.4202  y_predicted =  13.20703125  Difference =  1.2131687499999995\n",
      "y_test =  13.5157  y_predicted =  12.703125  Difference =  0.8125750000000007\n",
      "y_test =  13.9226  y_predicted =  12.65234375  Difference =  1.2702562499999992\n",
      "y_test =  13.3973  y_predicted =  13.34375  Difference =  0.05354999999999954\n",
      "y_test =  13.7892  y_predicted =  13.59375  Difference =  0.19544999999999924\n",
      "y_test =  12.7835  y_predicted =  12.7890625  Difference =  0.005562499999999915\n",
      "y_test =  12.8722  y_predicted =  13.08984375  Difference =  0.21764375000000058\n",
      "y_test =  12.058  y_predicted =  12.49609375  Difference =  0.43809375000000017\n",
      "y_test =  13.5787  y_predicted =  13.29296875  Difference =  0.28573124999999955\n",
      "y_test =  14.0613  y_predicted =  13.14453125  Difference =  0.9167687499999992\n",
      "y_test =  13.8038  y_predicted =  13.4375  Difference =  0.36630000000000074\n",
      "y_test =  13.2791  y_predicted =  13.50390625  Difference =  0.22480625000000032\n",
      "y_test =  14.2327  y_predicted =  13.62109375  Difference =  0.6116062499999995\n",
      "y_test =  12.687000000000001  y_predicted =  14.24609375  Difference =  1.5590937499999988\n",
      "y_test =  15.0997  y_predicted =  14.16796875  Difference =  0.9317312500000003\n",
      "y_test =  13.3046  y_predicted =  13.53515625  Difference =  0.23055624999999935\n",
      "y_test =  14.307  y_predicted =  12.77734375  Difference =  1.5296562500000004\n",
      "y_test =  13.8333  y_predicted =  13.2109375  Difference =  0.6223624999999995\n",
      "y_test =  10.4038  y_predicted =  11.59765625  Difference =  1.1938562499999996\n",
      "y_test =  14.3649  y_predicted =  13.59765625  Difference =  0.7672437500000004\n",
      "y_test =  13.5799  y_predicted =  12.3984375  Difference =  1.1814625000000003\n",
      "y_test =  13.5301  y_predicted =  12.9609375  Difference =  0.5691624999999991\n",
      "y_test =  15.0414  y_predicted =  13.53125  Difference =  1.5101499999999994\n",
      "y_test =  10.8938  y_predicted =  12.26953125  Difference =  1.3757312499999994\n",
      "y_test =  12.3558  y_predicted =  13.5859375  Difference =  1.2301374999999997\n",
      "y_test =  14.3335  y_predicted =  14.140625  Difference =  0.1928750000000008\n",
      "y_test =  12.024000000000001  y_predicted =  13.0  Difference =  0.9759999999999991\n",
      "y_test =  12.9242  y_predicted =  12.3671875  Difference =  0.5570125000000008\n",
      "y_test =  12.0399  y_predicted =  11.7109375  Difference =  0.3289624999999994\n",
      "y_test =  13.322000000000001  y_predicted =  13.33203125  Difference =  0.010031249999999048\n",
      "y_test =  14.2268  y_predicted =  13.2421875  Difference =  0.9846125000000008\n",
      "y_test =  14.0173  y_predicted =  13.015625  Difference =  1.0016750000000005\n",
      "y_test =  14.2104  y_predicted =  13.1875  Difference =  1.0229\n",
      "y_test =  12.6095  y_predicted =  12.77734375  Difference =  0.1678437499999994\n",
      "y_test =  13.0823  y_predicted =  13.265625  Difference =  0.18332499999999996\n",
      "y_test =  9.7625  y_predicted =  11.7109375  Difference =  1.9484375000000007\n",
      "y_test =  11.6629  y_predicted =  11.828125  Difference =  0.1652249999999995\n",
      "y_test =  13.8247  y_predicted =  13.52734375  Difference =  0.29735625\n",
      "y_test =  13.0846  y_predicted =  12.6484375  Difference =  0.4361625\n",
      "y_test =  13.9714  y_predicted =  12.7890625  Difference =  1.1823374999999992\n",
      "y_test =  13.1866  y_predicted =  13.484375  Difference =  0.2977749999999997\n",
      "y_test =  12.4133  y_predicted =  11.68359375  Difference =  0.7297062499999996\n",
      "y_test =  14.4141  y_predicted =  13.5234375  Difference =  0.8906624999999995\n",
      "y_test =  11.6935  y_predicted =  11.71484375  Difference =  0.021343749999999773\n",
      "y_test =  11.0365  y_predicted =  11.80859375  Difference =  0.7720937499999998\n",
      "y_test =  10.9803  y_predicted =  11.76171875  Difference =  0.7814187500000003\n",
      "y_test =  13.3031  y_predicted =  12.05078125  Difference =  1.2523187500000006\n",
      "y_test =  13.6304  y_predicted =  13.5078125  Difference =  0.12258749999999985\n",
      "y_test =  12.699000000000002  y_predicted =  13.68359375  Difference =  0.9845937499999984\n",
      "y_test =  11.9871  y_predicted =  11.80859375  Difference =  0.17850624999999987\n",
      "y_test =  14.315  y_predicted =  12.46484375  Difference =  1.8501562499999995\n",
      "y_test =  13.3969  y_predicted =  13.1875  Difference =  0.20940000000000047\n",
      "y_test =  10.3066  y_predicted =  11.68359375  Difference =  1.3769937500000005\n",
      "y_test =  12.2496  y_predicted =  12.2578125  Difference =  0.008212500000000844\n",
      "y_test =  11.9293  y_predicted =  13.24609375  Difference =  1.3167937500000004\n",
      "y_test =  12.39  y_predicted =  11.73828125  Difference =  0.6517187500000006\n",
      "y_test =  12.2521  y_predicted =  12.953125  Difference =  0.7010249999999996\n",
      "y_test =  10.7266  y_predicted =  11.65234375  Difference =  0.9257437500000005\n",
      "y_test =  11.7367  y_predicted =  11.6328125  Difference =  0.1038875000000008\n",
      "y_test =  12.5675  y_predicted =  11.78515625  Difference =  0.7823437500000008\n",
      "y_test =  13.529000000000002  y_predicted =  13.48046875  Difference =  0.04853125000000169\n",
      "y_test =  11.6918  y_predicted =  11.69921875  Difference =  0.007418749999999363\n",
      "y_test =  13.8477  y_predicted =  13.5390625  Difference =  0.3086374999999997\n",
      "y_test =  13.2472  y_predicted =  12.03125  Difference =  1.2159499999999994\n",
      "y_test =  13.3062  y_predicted =  13.4296875  Difference =  0.12348749999999953\n",
      "y_test =  11.4509  y_predicted =  11.98828125  Difference =  0.5373812499999993\n",
      "y_test =  13.9545  y_predicted =  13.4375  Difference =  0.5169999999999995\n",
      "y_test =  10.7229  y_predicted =  12.0625  Difference =  1.3396000000000008\n",
      "y_test =  13.8584  y_predicted =  13.609375  Difference =  0.2490249999999996\n",
      "y_test =  12.4599  y_predicted =  13.17578125  Difference =  0.7158812500000007\n",
      "y_test =  12.7126  y_predicted =  13.5234375  Difference =  0.8108374999999999\n",
      "y_test =  10.9531  y_predicted =  12.3203125  Difference =  1.3672125000000008\n",
      "y_test =  9.9156  y_predicted =  12.515625  Difference =  2.6000250000000005\n",
      "y_test =  12.1313  y_predicted =  12.43359375  Difference =  0.30229375000000047\n",
      "y_test =  14.6099  y_predicted =  12.78125  Difference =  1.8286499999999997\n",
      "y_test =  11.2402  y_predicted =  11.796875  Difference =  0.5566750000000003\n",
      "y_test =  11.5125  y_predicted =  11.703125  Difference =  0.1906250000000007\n",
      "y_test =  14.2225  y_predicted =  13.5390625  Difference =  0.6834375000000001\n",
      "y_test =  15.0699  y_predicted =  12.79296875  Difference =  2.2769312500000005\n",
      "y_test =  12.5418  y_predicted =  13.2421875  Difference =  0.7003874999999997\n",
      "y_test =  12.8224  y_predicted =  13.5703125  Difference =  0.7479125\n",
      "y_test =  13.6226  y_predicted =  12.921875  Difference =  0.7007250000000003\n",
      "y_test =  11.274000000000001  y_predicted =  11.6796875  Difference =  0.4056874999999991\n",
      "y_test =  12.914000000000001  y_predicted =  13.35546875  Difference =  0.4414687499999985\n",
      "y_test =  14.9256  y_predicted =  14.26171875  Difference =  0.6638812499999993\n",
      "y_test =  14.4105  y_predicted =  13.21875  Difference =  1.1917500000000008\n",
      "y_test =  13.065999999999999  y_predicted =  12.0859375  Difference =  0.980062499999999\n",
      "y_test =  12.0688  y_predicted =  13.24609375  Difference =  1.1772937500000005\n",
      "y_test =  13.269  y_predicted =  12.84375  Difference =  0.42525000000000013\n",
      "y_test =  10.3145  y_predicted =  12.59765625  Difference =  2.2831562499999993\n",
      "y_test =  13.0539  y_predicted =  12.984375  Difference =  0.0695250000000005\n",
      "y_test =  10.6551  y_predicted =  12.3515625  Difference =  1.6964625000000009\n",
      "y_test =  12.2178  y_predicted =  11.8359375  Difference =  0.38186250000000044\n",
      "y_test =  13.8772  y_predicted =  13.546875  Difference =  0.3303250000000002\n",
      "y_test =  13.1253  y_predicted =  13.01953125  Difference =  0.1057687499999993\n"
     ]
    }
   ],
   "source": [
    "for y1, y2 in zip(y_test, predictions):\n",
    "    print(\"y_test = \", y1, \" y_predicted = \", y2, \" Difference = \", abs(y1 - y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x10e542448>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
